{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mbysKdwnJm1k"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o8vT1yT3naTD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FVfFz8T7ngon"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48OnSrxip6D9"
   },
   "source": [
    "#Подготовка Данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wzKN58RZnrat"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zv4OktKDGNd9",
    "outputId": "385cb2eb-cab3-4b20-a344-99bf40124ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25062 entries, 0 to 25061\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Name              25062 non-null  object \n",
      " 1   Category          25062 non-null  object \n",
      " 2   Brand             25061 non-null  object \n",
      " 3   Seller            25031 non-null  object \n",
      " 4   Color             127 non-null    object \n",
      " 5   Comments          25062 non-null  float64\n",
      " 6   Final price       25062 non-null  float64\n",
      " 7   Max price         25062 non-null  float64\n",
      " 8   Min price         25062 non-null  float64\n",
      " 9   Average price     19264 non-null  float64\n",
      " 10  Sales             25062 non-null  float64\n",
      " 11  Days in stock     25062 non-null  float64\n",
      " 12  Days with sales   25062 non-null  int64  \n",
      " 13  Rating            25062 non-null  object \n",
      " 14  Basic Sale        25062 non-null  float64\n",
      " 15  Basic Sale Price  25062 non-null  float64\n",
      " 16  Base price        25062 non-null  float64\n",
      " 17  full_category     25062 non-null  object \n",
      "dtypes: float64(10), int64(1), object(7)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUbuH_ojoq1p"
   },
   "source": [
    "Добавим среднюю цену среди категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w-9kCa6ghC6B"
   },
   "outputs": [],
   "source": [
    "avg_price_per_category = []\n",
    "for cat in np.unique(train_data['Category'].values):\n",
    "    # print(cat)\n",
    "    avg_price_per_category.append(train_data[train_data['Category'] == cat]['Average price'].mean())\n",
    "    cat_mean_price = train_data[train_data['Category'] == cat]['Average price'].mean()\n",
    "    train_data.loc[train_data['Category'] == cat, 'Avg_price_per_category'] = cat_mean_price\n",
    "# print(avg_price_per_category)\n",
    "# train_data.head()\n",
    "\n",
    "avg_price_per_category = []\n",
    "for cat in np.unique(test_data['Category'].values):\n",
    "    # print(cat)\n",
    "    avg_price_per_category.append(test_data[test_data['Category'] == cat]['Average price'].mean())\n",
    "    cat_mean_price = test_data[test_data['Category'] == cat]['Average price'].mean()\n",
    "    test_data.loc[test_data['Category'] == cat, 'Avg_price_per_category'] = cat_mean_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbE3j0acox0h"
   },
   "source": [
    "Добавим фичу, если средняя цена продажи не выше чем средняя цена по сегменту - 1, иначе 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zwW4iGpiowwA"
   },
   "outputs": [],
   "source": [
    "train_data['avg_price_not_more_than_evg_cat'] = np.where((train_data['Avg_price_per_category'] >= train_data['Average price']), 1, 0)\n",
    "train_data['avg_price_not_more_than_evg_cat'] = train_data['avg_price_not_more_than_evg_cat'].astype('object')\n",
    "\n",
    "test_data['avg_price_not_more_than_evg_cat'] = np.where((test_data['Avg_price_per_category'] >= test_data['Average price']), 1, 0)\n",
    "test_data['avg_price_not_more_than_evg_cat'] = test_data['avg_price_not_more_than_evg_cat'].astype('object')\n",
    "\n",
    "ratings = train_data['Rating'].values\n",
    "num_ratings = [int(rating.split(',')[0]) for rating in ratings]\n",
    "train_data['Rating'] = num_ratings\n",
    "\n",
    "ratings = test_data['Rating'].values\n",
    "num_ratings = [int(rating.split(',')[0]) for rating in ratings]\n",
    "test_data['Rating'] = num_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YQuXnVcE-yq",
    "outputId": "cfa6139b-448c-4a29-a488-5e00935a2318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.590824942430126\n"
     ]
    }
   ],
   "source": [
    "# print(f\"mean: {train_data['Comments'][:len(train_data['Comments'].values)].mean()}\")\n",
    "print(f\"mean: {train_data.sort_values(by='Comments').loc[:len(train_data.sort_values(by='Comments')['Comments'].values)-1, 'Comments'].mean()}\")\n",
    "\n",
    "# train_data.sort_values(by='Comments').loc[:len(train_data.sort_values(by='Comments')['Comments'].values)-1, 'Comments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5bh4pEYqqA5f"
   },
   "outputs": [],
   "source": [
    "train_data['comments_more_than_avg'] = (train_data['Comments'] > 5).astype('object')\n",
    "# pd.crosstab(train_data['comments_more_than_avg'], train_data['Sales'], margins=True)\n",
    "test_data['comments_more_than_avg'] = (test_data['Comments'] > 5).astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OU9dOpi_gl9"
   },
   "source": [
    "Удаляем элементы с продажами более 1000 (меньше 1% всех записей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n-pjTyhRHdAZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_data = train_data[train_data['Sales'] < 1000.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8B_EflQ6cG0",
    "outputId": "fb93fa60-b570-4581-ae5f-4553fd07f7ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25062 entries, 0 to 25061\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Name                             25062 non-null  object \n",
      " 1   Category                         25062 non-null  object \n",
      " 2   Brand                            25061 non-null  object \n",
      " 3   Seller                           25031 non-null  object \n",
      " 4   Color                            127 non-null    object \n",
      " 5   Comments                         25062 non-null  float64\n",
      " 6   Final price                      25062 non-null  float64\n",
      " 7   Max price                        25062 non-null  float64\n",
      " 8   Min price                        25062 non-null  float64\n",
      " 9   Average price                    19264 non-null  float64\n",
      " 10  Sales                            25062 non-null  float64\n",
      " 11  Days in stock                    25062 non-null  float64\n",
      " 12  Days with sales                  25062 non-null  int64  \n",
      " 13  Rating                           25062 non-null  int64  \n",
      " 14  Basic Sale                       25062 non-null  float64\n",
      " 15  Basic Sale Price                 25062 non-null  float64\n",
      " 16  Base price                       25062 non-null  float64\n",
      " 17  full_category                    25062 non-null  object \n",
      " 18  Avg_price_per_category           25059 non-null  float64\n",
      " 19  avg_price_not_more_than_evg_cat  25062 non-null  object \n",
      " 20  comments_more_than_avg           25062 non-null  object \n",
      "dtypes: float64(11), int64(2), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DEGDOnVsp4kz"
   },
   "outputs": [],
   "source": [
    "def deleteId(ds):\n",
    "    return ds.drop(columns='Id')\n",
    "\n",
    "def deleteNaN(train_ds, test_ds, critval):\n",
    "    fullsize = train_ds.shape[0]\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    for feature in new_train.columns:\n",
    "        nulls = new_train[feature].isnull().sum()\n",
    "        percent = nulls / fullsize\n",
    "        # если доля пустых значений превышает critval - столбец не информативен,\n",
    "        # можно его выбросить\n",
    "        if (percent > critval):\n",
    "            new_train = new_train.drop(columns=feature)\n",
    "            new_test = new_test.drop(columns=feature)\n",
    "    return new_train, new_test\n",
    "\n",
    "def convertToNumeric(train_ds, test_ds):\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    LE = LabelEncoder()\n",
    "    for feature in new_train.columns:\n",
    "        if (new_train[feature].dtype == 'object'):\n",
    "            new_train[feature] = LE.fit_transform(new_train[feature])\n",
    "            new_test[feature] = LE.fit_transform(new_test[feature])\n",
    "    return new_train, new_test\n",
    "\n",
    "train = train_data.drop_duplicates()\n",
    "\n",
    "# train = train.drop(columns='Id')\n",
    "train = train.drop(columns='Color')\n",
    "train = train.drop(columns='Base price')\n",
    "train = train.drop(columns='Basic Sale Price')\n",
    "\n",
    "test = test_data.drop(columns='Id')\n",
    "test = test.drop(columns='Color')\n",
    "test = test.drop(columns='Base price')\n",
    "test = test.drop(columns='Basic Sale Price')\n",
    "\n",
    "train, test = deleteNaN(train, test, critval=0.8)\n",
    "train, test = convertToNumeric(train, test)\n",
    "\n",
    "train_y = train['Sales'].values\n",
    "train_X = train.drop(columns='Sales').values\n",
    "val_test = test.values\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_y, test_size=0.1, random_state=7)  # random_state=98987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkaGEa8Zp5fd"
   },
   "source": [
    "#Избавимся от NaN значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "o-JwYRLZq88o"
   },
   "outputs": [],
   "source": [
    "strategies = ['mean', 'median', 'most_frequent']\n",
    "imputer = SimpleImputer(strategy=strategies[2])\n",
    "trainX = imputer.fit_transform(train_x)\n",
    "testX = imputer.fit_transform(test_x)\n",
    "val_test_x = imputer.fit_transform(val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MCgRmuVQq_v6"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)\n",
    "val_test_x = scaler.transform(val_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEmNAxqcrBeV",
    "outputId": "d1b0dc74-5779-4d3d-b21e-9958888f5a21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22086, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9cg0kNU5HFq",
    "outputId": "35ca7216-813e-4c1a-b7a8-d9b9aacd53ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10741, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6VcRZ4sDQQ"
   },
   "source": [
    "#Метрика **SMAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iNj1FN7QsLYG"
   },
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        tmp = 2 * np.abs(F-A) / (np.abs(A) + np.abs(F))\n",
    "    tmp[np.isnan(tmp)] = 0\n",
    "    return np.sum(tmp) / len(tmp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "r4i67YSlsKKP"
   },
   "outputs": [],
   "source": [
    "def check_error(preds, gt):\n",
    "    print('SMAPE Error:', smape(np.round(preds), gt))\n",
    "    # print('RMSE Error:', mean_squared_error(np.round((np.abs(preds))), gt, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39MSCs_5r87I"
   },
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "00-ygxl1r-YN"
   },
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'criterion':(['absolute_error']), \n",
    "#     'max_depth':  [100, 500, 100],\n",
    "#     'n_estimators': [40, 50, 60, 55],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': range(10, 71, 20)}\n",
    "\n",
    "# model = RandomForestRegressor()\n",
    "# rf_gs_model = GridSearchCV(model, parameters)\n",
    "# rf_gs_model.fit(trainX[:300], train_y[:300])\n",
    "# print(f\"Best parameters: {rf_gs_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kKD60gjDsiL7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Error: 20.986130844369683\n"
     ]
    }
   ],
   "source": [
    "last_rf_best_params = {\n",
    "    'criterion': 'absolute_error', \n",
    "    'max_depth': 350,  # 300\n",
    "    'n_estimators': 70, # 70\n",
    "    'min_samples_leaf': 4, # 3\n",
    "    'min_samples_split': 50 # 50\n",
    "}\n",
    "\n",
    "# random_forest = RandomForestRegressor(**rf_gs_model.best_params_)\n",
    "random_forest = RandomForestRegressor(**last_rf_best_params) \n",
    "random_forest.fit(trainX, train_y)\n",
    "check_error(random_forest.predict(testX), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xwk1vJQPw18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Error: 20.986130844369683\n",
      "[605.60714286  17.66428571  85.54285714 ...   0.          38.27857143\n",
      "  23.07142857]\n"
     ]
    }
   ],
   "source": [
    "check_error(random_forest.predict(testX), test_y)\n",
    "print(random_forest.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GfmGNeZmKyv"
   },
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "T7BHm5hwmJoR"
   },
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     \"learning_rate\": [0.1, 0.01, 0.075, 0.015],\n",
    "#     \"max_depth\": [3, 4, 10, 100],\n",
    "#     \"min_child_weight\": [3, 5, 7, 10],\n",
    "#     # \"n_estimators\": range(10, 51, 10),\n",
    "#     \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.],\n",
    "#     \"gamma\": [0.5, 0.7, 0.3, 1.],\n",
    "#     \"reg_lambda\": [0.6, 0.7, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.]\n",
    "# }\n",
    "\n",
    "# model = XGBRegressor(objective='reg:squarederror')\n",
    "# xgb_gs_model = GridSearchCV(model, parameters)\n",
    "# xgb_gs_model.fit(new_trainX, train_y)\n",
    "# print(f\"Best parameters: {xgb_gs_model.best_params_}\")\n",
    "\n",
    "# gridcv_xgb = xgb_gs_model.best_estimator_\n",
    "# check_error(np.round(gridcv_xgb.predict(new_testX)), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkavW-I_mPbj",
    "outputId": "528c32a2-a64f-4808-f641-67cc999a33fb"
   },
   "outputs": [],
   "source": [
    "# last_xgb_best_params = {\n",
    "#     \"learning_rate\": 0.035,\n",
    "#     \"max_depth\": 350,\n",
    "#     \"min_child_weight\": 14,\n",
    "#     \"n_estimators\": 50, \n",
    "#     \"subsample\": 0.9,\n",
    "#     # \"booster\": 'gbtree',\n",
    "#     \"reg_lambda\": 1.,\n",
    "#     \"gamma\": 0.3,\n",
    "#     'colsample_bytree': 0.9\n",
    "# }\n",
    "# xgb_reg = XGBRegressor(**last_xgb_best_params) \n",
    "# # xgb_reg = XGBRegressor(**xgb_gs_model.best_params_)\n",
    "# xgb_reg.fit(trainX, train_y)\n",
    "# check_error(np.round(xgb_reg.predict(testX)), test_y)\n",
    "\n",
    "# # xgb_reg.fit(new_trainX, train_y)\n",
    "# # check_error(np.round(xgb_reg.predict(new_testX)), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTSASGWvRUCv"
   },
   "source": [
    "#Соревы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y55nrbHTRhSX"
   },
   "outputs": [],
   "source": [
    "submission_path = '../submissions/submission.csv'\n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8wz3eL_JSOyL"
   },
   "outputs": [],
   "source": [
    "predictions = np.round(random_forest.predict(val_test_x))\n",
    "submission['Expected'] = predictions\n",
    "submission\n",
    "submission.to_csv('../submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "25rH9rrg9a8H"
   },
   "outputs": [],
   "source": [
    "# predictions = np.round(xgb_reg.predict(val_test_x))\n",
    "# submission['Expected'] = predictions\n",
    "# submission\n",
    "# submission.to_csv('submission_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
